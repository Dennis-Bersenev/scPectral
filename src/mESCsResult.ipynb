{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source publication for dataset: \n",
    "https://www.nature.com/articles/s41467-018-02866-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = 456\n",
    "n_genes = 100\n",
    "PWscores = np.zeros((n_cells, n_genes, n_genes))\n",
    "\n",
    "for i in range(n_cells):\n",
    "    path = \"./../data/TEsmESC/geneXgene{i}.csv\".format(i=(i+1))\n",
    "    df_temp = pd.read_csv(path)\n",
    "    PWscores[i, :, :] = np.copy(df_temp.values)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: <br />\n",
    "Make the graph! We got cells, and we got PW gene scores for all the cells! <br />\n",
    "What does a high score mean? It means that within the neighbourhood of that cell, the first gene is informative of the other gene! <br />\n",
    "Each entry of the matrix: PWscores[i, j, k] represents the transfer entropy score of j â†’ k in the neighbourhood of cell i. <br />\n",
    "Why's that significant? How does that help anyone?\n",
    "--> Read up on that! <br/> <br/>\n",
    "\n",
    "Steps: <br/>\n",
    "1. Get the OG data and remake the trajectory by just putting the most similar cells side-by-side <br/>\n",
    "2. Do the same with the PW network and see how the two compare <br/>\n",
    "(first two steps are just to get a sense of the cell manifold)<br/>\n",
    "3. Find high cost PATHS in each cell, i.e. represent each cell as an interaction network and find the highest entropy paths through it <br/>\n",
    "4. Use these as the edges of your hypergraph, and do this for all cells <br/>\n",
    "(it makes sense because we're interested in what gene pathways have high TE scores across cells)<br/>\n",
    "5. Spectral clustering hopefully reveals some developmentally critical genes<br/>\n",
    "(keep in mind this is a dataset of transcription factors!)<br/> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the path(s) with the maximum value(s) <br/>\n",
    "    - decide which values to keep <i>relative</i> to the <i>original maximum</i> value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, the entries in the matrix are weights for edges... what you want to ultimately output are the genes involved in the edges!\n",
    "# row/col index = row->col edge, i.e. entropy between gene_row->gene_col (TODO: or the reverse)\n",
    "# so you wanna output the row->col indices, and eventually map those back to gene names! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The informative gene pathway extraction algorithm\n",
    "(For now implemented as just an easy intuitive iterative solution, maybe later will attempt a numpy/C++ acceleration!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: right now it is just greedy bfs, but I want paths to be able to branch and for multiple nodes to all connect to a common node\n",
    "# eg. if you get 3-> 59, 18 -> 59 that outta be shown as 3&18 -> 59 (somehow)\n",
    "\"\"\"\n",
    "TODO: just build the incidence matrix as you go? each iteration adds a new set 'layer' of edges\n",
    "--> see notes !\n",
    "implement this proper (will write another function)\n",
    "\"\"\"\n",
    "def get_hyperedge_set(cell_index):\n",
    "\n",
    "    cell_nw = PWscores[cell_index, :, :]\n",
    "    \n",
    "    # init\n",
    "    paths = []\n",
    "    max_itrs = n_genes\n",
    "    itrs = 0\n",
    "    tolerance = np.max(cell_nw) * 0.2 # all scores within whatever % of the max\n",
    "    max_path_len = 0\n",
    "    max_path_len_prev = -1\n",
    "\n",
    "    for i in range(n_genes): #row is the predecessor node\n",
    "        index_max = np.argmax(cell_nw[i, :]) # index of max column is the successor (incident) node\n",
    "        \n",
    "        if cell_nw[i, index_max] > tolerance:\n",
    "            paths.append([i, index_max])\n",
    "\n",
    "    # update\n",
    "    while (max_itrs > itrs) and (max_path_len > max_path_len_prev):\n",
    "        max_path_len_prev = max_path_len\n",
    "        new_paths = deepcopy(paths) \n",
    "        for p in range(len(paths)):\n",
    "            path = paths[p]\n",
    "            if len(path) >= max_path_len:\n",
    "                row = path[-1]\n",
    "                index_max = np.argmax(cell_nw[row, :])\n",
    "                \n",
    "                if (cell_nw[row, index_max] > tolerance) and (index_max not in new_paths[p]):\n",
    "                    new_paths[p].append(index_max)\n",
    "\n",
    "        max_path_len = max( len(x) for x in new_paths )\n",
    "        itrs += 1\n",
    "        paths = deepcopy(new_paths)\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the hypergraph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: a simple canonical edge has the form of tail->head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merges tails with common heads to identify all the multi-arity relations to represent as hedges and updates the supplied incidence matrix with these final hedges.\n",
    "_edges: a list of tuples (tail_set, head_set) of all the initial single-tailed edges (note: they are sets, not lists!)\n",
    "B: a list of n_gene-sized integer numpy arrays to represent the incidence matrix to update.\n",
    "TODO: Test and be especially make sure Python's memory system isn't doing any weird reference copying and producing the wrong stuff!\n",
    "Note, all set operations return copies, so this SHOULD be okay.\n",
    "\"\"\"\n",
    "def merge_edges(_edges, B):\n",
    "    \n",
    "    # init\n",
    "    edges = deepcopy(_edges)\n",
    "    m = len(edges)\n",
    "\n",
    "    # Stop when there's only a single edge left (not possible to merge anything else)\n",
    "    while (m >= 2):\n",
    "        \n",
    "        new_edges = [] \n",
    "        for i in range(0, m, 1):\n",
    "            e1 = edges[i]\n",
    "            for j in range(i + 1, m, 1):\n",
    "                e2 = edges[j]\n",
    "                common_heads = e1[1].intersection(e2[1])\n",
    "                if (len(common_heads) > 0):\n",
    "                    \n",
    "                    # The new edge\n",
    "                    new_tails = e1[0].union(e2[0]) \n",
    "                    new_edge = ([new_tails, common_heads])\n",
    "                    new_edges.append(new_edge)\n",
    "\n",
    "                    # Updating old edges (their head sets)\n",
    "                    e1[1] = set(e1[1] - common_heads)\n",
    "                    e2[1] = set(e2[1] - common_heads)\n",
    "\n",
    "        \n",
    "        # Add all edges with non-null head sets to the incidence matrix!\n",
    "        for edge in edges:\n",
    "            col = np.zeros(n_genes)\n",
    "            if len(edge[1]) > 0:\n",
    "                # TODO: handle weights... how? Each hedge gets assigned a single weight,and those get stored in a different matrix/use a function. \n",
    "                for tail in edge[0]:\n",
    "                    col[tail] = -1\n",
    "                for head in edge[1]:\n",
    "                    col[head] = 1\n",
    "\n",
    "                B.append(np.copy(col))\n",
    "        \n",
    "        edges = deepcopy(new_edges)\n",
    "        m = len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Creates a hypergraph, represented using an incidence matrix, from the given cell's PW gene network. \n",
    "cell_index: the index into the PWscores array for the desired cell.\n",
    "p: percentage parameter to use in tolerance calculation; decides which relationships relative to the maximum PW TE. \n",
    "returns: B the incidence matrix of the constructed hypergraph. \n",
    "\"\"\"\n",
    "def construct_hyper_graph(cell_index, p):\n",
    "    # init\n",
    "    unique_genes = set()\n",
    "    cell_nw = PWscores[cell_index, :, :]\n",
    "\n",
    "    # The incidence matrix (might use different data structure)\n",
    "    B = []\n",
    "\n",
    "    # all scores within whatever % of the max\n",
    "    tolerance = np.max(cell_nw) * p\n",
    "\n",
    "    tails = set(np.arange(start=0, stop=n_genes, step=1))\n",
    "\n",
    "    # debug var\n",
    "    count = 0\n",
    "\n",
    "    # TODO: TEST IT ALL \n",
    "    while (len(tails) > 0):\n",
    "        edges = []\n",
    "        new_tails = set()\n",
    "        heads_to_remember = set()\n",
    "\n",
    "        for tail in tails:\n",
    "            heads = set(np.flatnonzero(cell_nw[tail, :] > tolerance))\n",
    "            \n",
    "            # Termination condition: once there's no new heads added this never gets hit, no new tails get added and the tail set becomes null at the end of while itr\n",
    "            if (len(heads) > 0) and (heads.isdisjoint(unique_genes)):\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "                for head in heads:\n",
    "                    # error handling\n",
    "                    if (cell_nw[tail, head] <= tolerance):\n",
    "                        print(\"BIG BUG\") # TODO: keep this error cond here and handle it better!\n",
    "\n",
    "                    # update the next-level tails\n",
    "                    new_tails.add(head)\n",
    "                    \n",
    "                    # TODO: maybe make the set of all heads for this level here and wait till the end of the iteration to deep copy it over?\n",
    "                    heads_to_remember.add(head)\n",
    "                    \n",
    "                # update the edge set for this hgraph level\n",
    "                tail_as_set = set()\n",
    "                tail_as_set.add(tail)\n",
    "                edges.append([tail_as_set, heads])\n",
    "        \n",
    "        # update the unique heads set\n",
    "        # for e in edges:\n",
    "        #     for h in e[1]:\n",
    "        #         unique_genes.add(h)\n",
    "        for h in heads_to_remember:\n",
    "            unique_genes.add(h)\n",
    "\n",
    "        merge_edges(edges, B)\n",
    "        tails = set(deepcopy(new_tails))\n",
    "    \n",
    "    return B\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with sets\n",
    "my_set = set()\n",
    "my_set.add(4)\n",
    "my_set.add(2)\n",
    "my_set.add(4)\n",
    "my_set.add(3)\n",
    "\n",
    "b_set = set()\n",
    "b_set.add(2)\n",
    "b_set.add(3)\n",
    "\n",
    "# this code works!\n",
    "a_set = set(np.arange(0, 3))\n",
    "\n",
    "l1 = list(deepcopy(a_set))\n",
    "my_set = my_set - b_set\n",
    "len(my_set)\n",
    "a_set.intersection(b_set)\n",
    "b_set = set(deepcopy(a_set))\n",
    "for a in a_set:\n",
    "    # print(type(int(a)))\n",
    "    my_set.add(a)\n",
    "\n",
    "null_s = set()\n",
    "b_set = set(deepcopy(null_s))\n",
    "my_set.isdisjoint(a_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_cells):\n",
    "    G = construct_hyper_graph(i, 0.1)\n",
    "    for e in G:\n",
    "        # if (np.sum(e < 0)) >= 2:\n",
    "            # print(\"This SHOULD happen, you know from the pathway function, so either this is a bug OR the uniqueness invariant is too strong!\\n\")\n",
    "        if (np.sum(e < 0) == 0):\n",
    "            print(\"bug\")\n",
    "        if (np.sum(e > 0) == 0):\n",
    "            print(\"a lesser bug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum(G[2] < 0) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrally clustering the hypergraph\n",
    "(hopefully revealing the informative gene pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# # our adjacency matrix\n",
    "# print(\"Adjacency Matrix:\")\n",
    "# print(A)\n",
    "\n",
    "# # Adjacency Matrix:\n",
    "# # [[0. 1. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
    "# #  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    "# #  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "# #  [0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
    "# #  [0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
    "# #  [1. 0. 0. 1. 1. 0. 1. 1. 0. 0.]\n",
    "# #  [0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
    "# #  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
    "# #  [1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "# #  [1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
    "\n",
    "# # diagonal matrix\n",
    "# D = np.diag(A.sum(axis=1))\n",
    "\n",
    "# # graph laplacian\n",
    "# L = D-A\n",
    "\n",
    "# # eigenvalues and eigenvectors\n",
    "# vals, vecs = np.linalg.eig(L)\n",
    "\n",
    "# # sort these based on the eigenvalues\n",
    "# vecs = vecs[:,np.argsort(vals)]\n",
    "# vals = vals[np.argsort(vals)]\n",
    "\n",
    "# # kmeans on first three vectors with nonzero eigenvalues\n",
    "# kmeans = KMeans(n_clusters=4)\n",
    "# kmeans.fit(vecs[:,1:4])\n",
    "# colors = kmeans.labels_\n",
    "\n",
    "# print(\"Clusters:\", colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
