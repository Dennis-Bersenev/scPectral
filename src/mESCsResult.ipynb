{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source publication for dataset: \n",
    "https://www.nature.com/articles/s41467-018-02866-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cells = 456\n",
    "n_genes = 100\n",
    "PWscores = np.zeros((n_cells, n_genes, n_genes))\n",
    "\n",
    "for i in range(n_cells):\n",
    "    path = \"./../data/TEsmESC/geneXgene{i}.csv\".format(i=(i+1))\n",
    "    df_temp = pd.read_csv(path)\n",
    "    PWscores[i, :, :] = np.copy(df_temp.values)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: <br />\n",
    "Make the graph! We got cells, and we got PW gene scores for all the cells! <br />\n",
    "What does a high score mean? It means that within the neighbourhood of that cell, the first gene is informative of the other gene! <br />\n",
    "Each entry of the matrix: PWscores[i, j, k] represents the transfer entropy score of j â†’ k in the neighbourhood of cell i. <br />\n",
    "Why's that significant? How does that help anyone?\n",
    "--> Read up on that! <br/> <br/>\n",
    "\n",
    "Steps: <br/>\n",
    "1. Get the OG data and remake the trajectory by just putting the most similar cells side-by-side <br/>\n",
    "2. Do the same with the PW network and see how the two compare <br/>\n",
    "(first two steps are just to get a sense of the cell manifold)<br/>\n",
    "3. Find high cost PATHS in each cell, i.e. represent each cell as an interaction network and find the highest entropy paths through it <br/>\n",
    "4. Use these as the edges of your hypergraph, and do this for all cells <br/>\n",
    "(it makes sense because we're interested in what gene pathways have high TE scores across cells)<br/>\n",
    "5. Spectral clustering hopefully reveals some developmentally critical genes<br/>\n",
    "(keep in mind this is a dataset of transcription factors!)<br/> \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the path(s) with the maximum value(s) <br/>\n",
    "    - decide which values to keep <i>relative</i> to the <i>original maximum</i> value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, the entries in the matrix are weights for edges... what you want to ultimately output are the genes involved in the edges!\n",
    "# row/col index = row->col edge, i.e. entropy between gene_row->gene_col (TODO: or the reverse)\n",
    "# so you wanna output the row->col indices, and eventually map those back to gene names! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The informative gene pathway extraction algorithm\n",
    "(For now implemented as just an easy intuitive iterative solution, maybe later will attempt a numpy/C++ acceleration!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: right now it is just greedy bfs, but I want paths to be able to branch and for multiple nodes to all connect to a common node\n",
    "# eg. if you get 3-> 59, 18 -> 59 that outta be shown as 3&18 -> 59 (somehow)\n",
    "\"\"\"\n",
    "TODO: just build the incidence matrix as you go? each iteration adds a new set 'layer' of edges\n",
    "--> see notes !\n",
    "implement this proper (will write another function)\n",
    "\"\"\"\n",
    "def get_hyperedge_set(cell_index):\n",
    "\n",
    "    cell_nw = PWscores[cell_index, :, :]\n",
    "    \n",
    "    # init\n",
    "    paths = []\n",
    "    max_itrs = n_genes\n",
    "    itrs = 0\n",
    "    tolerance = np.max(cell_nw) * 0.2 # all scores within whatever % of the max\n",
    "    max_path_len = 0\n",
    "    max_path_len_prev = -1\n",
    "\n",
    "    for i in range(n_genes): #row is the predecessor node\n",
    "        index_max = np.argmax(cell_nw[i, :]) # index of max column is the successor (incident) node\n",
    "        \n",
    "        if cell_nw[i, index_max] > tolerance:\n",
    "            paths.append([i, index_max])\n",
    "\n",
    "    # update\n",
    "    while (max_itrs > itrs) and (max_path_len > max_path_len_prev):\n",
    "        max_path_len_prev = max_path_len\n",
    "        new_paths = deepcopy(paths) \n",
    "        for p in range(len(paths)):\n",
    "            path = paths[p]\n",
    "            if len(path) >= max_path_len:\n",
    "                row = path[-1]\n",
    "                index_max = np.argmax(cell_nw[row, :])\n",
    "                \n",
    "                if (cell_nw[row, index_max] > tolerance) and (index_max not in new_paths[p]):\n",
    "                    new_paths[p].append(index_max)\n",
    "\n",
    "        max_path_len = max( len(x) for x in new_paths )\n",
    "        itrs += 1\n",
    "        paths = deepcopy(new_paths)\n",
    "    \n",
    "    return paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the hypergraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we here\n",
      "we here\n",
      "len(A) = 2 should match the count = 2\n"
     ]
    }
   ],
   "source": [
    "# TODO implement and test\n",
    "cell_index = 0\n",
    "\n",
    "cell_nw = PWscores[cell_index, :, :]\n",
    "\n",
    "# adjacency matrix (might use different data structure)\n",
    "A = []\n",
    "\n",
    "# all scores within whatever % of the max\n",
    "tolerance = np.max(cell_nw) * 0.5 \n",
    "\n",
    "count = 0\n",
    "# getting the first hyperedges (hedges)\n",
    "for tail in range(n_genes):\n",
    "    heads = np.flatnonzero(cell_nw[tail, :] > tolerance)\n",
    "    \n",
    "    if len(heads) > 0:\n",
    "        \n",
    "        # debug var\n",
    "        count += 1\n",
    "\n",
    "        # add an edge for this set\n",
    "        edge = np.zeros(n_genes)\n",
    "        edge[tail] = -1 # TODO: handle weights... how? Each hedge gets assigned a single weight,and those get stored in a different matrix/use a function. \n",
    "        \n",
    "        for head in heads:\n",
    "            # error handling\n",
    "            if (cell_nw[tail, head] <= tolerance):\n",
    "                print(\"BUG\") # no bugs! but keep this error cond here and handle it better!\n",
    "            \n",
    "            edge[head] = 1\n",
    "\n",
    "        A.append(np.copy(edge))\n",
    "\n",
    "    else:\n",
    "        continue    \n",
    "\n",
    "\n",
    "# print(\"len(A) = {l} should match the count = {a}\".format(l=len(A), a=count))\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a simple canonical edge: tail->head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merges tails with common heads to identify all the multi-arity relations to represent as hedges and updates the supplied incidence matrix with these final hedges.\n",
    "_edges: a list of tuples (tail_set, head_set) of all the initial single-tailed edges (note: they are sets, not lists!)\n",
    "B: a list of n_gene-sized integer numpy arrays to represent the incidence matrix to update.\n",
    "TODO: Test and be especially make sure Python's memory system isn't doing any weird reference copying and producing the wrong stuff!\n",
    "Note, all set operations return copies, so this SHOULD be okay.\n",
    "\"\"\"\n",
    "def merge_edges(_edges, B):\n",
    "    \n",
    "    # init\n",
    "    edges = deepcopy(_edges)\n",
    "    m = len(edges)\n",
    "\n",
    "    # Stop when there's only a single edge left (not possible to merge anything else)\n",
    "    while (m >= 2):\n",
    "        \n",
    "        new_edges = [] \n",
    "        for i in range(m):\n",
    "            e1 = edges[i]\n",
    "            for j in range(start = i + 1, stop = m, step = 1):\n",
    "                e2 = edges[j]\n",
    "                common_heads = e1[1].intersection(e2[1])\n",
    "                if (len(common_heads) > 0):\n",
    "                    \n",
    "                    # The new edge\n",
    "                    new_tails = e1[0].intersection(e2[0]) # should be the same as doing a union of the tails\n",
    "                    new_edge = (new_tails, common_heads)\n",
    "                    new_edges.append(new_edge)\n",
    "\n",
    "                    # Updating old edges (their head sets)\n",
    "                    e1[1] = e1[1] - common_heads\n",
    "                    e2[1] = e2[1] - common_heads\n",
    "\n",
    "        \n",
    "        # Add all edges with non-null head sets to the incidence matrix!\n",
    "        for edge in edges:\n",
    "            col = np.zeros(n_genes)\n",
    "            if len(edge[1] > 0):\n",
    "                # TODO: handle weights... how? Each hedge gets assigned a single weight,and those get stored in a different matrix/use a function. \n",
    "                for tail in edge[0]:\n",
    "                    col[tail] = -1\n",
    "                for head in edge[1]:\n",
    "                    col[head] = 1\n",
    "\n",
    "                B.append(np.copy(col))\n",
    "        \n",
    "        edges = deepcopy(new_edges)\n",
    "        m = len(edges)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "\"\"\"\n",
    "def construct_hyper_graph(cell_index):\n",
    "    # init\n",
    "    unique_genes = set()\n",
    "    cell_nw = PWscores[cell_index, :, :]\n",
    "\n",
    "    # The incidence matrix (might use different data structure)\n",
    "    B = []\n",
    "\n",
    "    # all scores within whatever % of the max\n",
    "    tolerance = np.max(cell_nw) * 0.5 \n",
    "\n",
    "    tails = set(np.arange(start=0, stop=n_genes, step=1))\n",
    "\n",
    "    # debug var\n",
    "    count = 0\n",
    "\n",
    "    # TODO: TEST IT ALL \n",
    "    while (len(tails) > 0):\n",
    "        edges = []\n",
    "        new_tails = set()\n",
    "\n",
    "        for tail in tails:\n",
    "            heads = set(np.flatnonzero(cell_nw[tail, :] > tolerance))\n",
    "\n",
    "            # TODO: This conditional is something to test, in general \n",
    "            # Termination condition: once there's no new heads added this never gets hit, no new tails get added and the tails set is set null at the end of while itr\n",
    "            if (len(heads) > 0) & (np.sum(np.isin(heads, unique_genes)) == 0):\n",
    "                \n",
    "                count += 1\n",
    "                \n",
    "                for head in heads:\n",
    "                    # error handling\n",
    "                    if (cell_nw[tail, head] <= tolerance):\n",
    "                        print(\"BUG\") # no bugs! but keep this error cond here and handle it better!\n",
    "\n",
    "                    # update the unique heads set and next-level tails\n",
    "                    unique_genes.add(head)\n",
    "                    new_tails.add(head)\n",
    "                \n",
    "                # update the edge set for this hgraph level\n",
    "                edges.append(tail, heads)\n",
    "\n",
    "            else:\n",
    "                continue    \n",
    "\n",
    "        merge_edges(edges, B)\n",
    "        tails = deepcopy(new_tails)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Playing with sets\n",
    "my_set = set()\n",
    "my_set.add(4)\n",
    "my_set.add(2)\n",
    "my_set.add(4)\n",
    "my_set.add(3)\n",
    "\n",
    "b_set = set()\n",
    "b_set.add(2)\n",
    "b_set.add(3)\n",
    "\n",
    "# this code works!\n",
    "a_set = set(np.arange(0, 3))\n",
    "\n",
    "l1 = list(deepcopy(a_set))\n",
    "my_set = my_set - b_set\n",
    "len(my_set)\n",
    "a_set.intersection(b_set)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrally clustering the hypergraph\n",
    "(hopefully revealing the informative gene pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14839491, -0.11614054, -0.12934791, ..., -0.00600811,\n",
       "        -0.01207833, -0.00518973],\n",
       "       [-0.06968851,  0.06080648, -0.1163808 , ..., -0.01349286,\n",
       "        -0.01534495, -0.01875696],\n",
       "       [-0.05955119,  0.05246104,  0.00081543, ..., -0.01040518,\n",
       "        -0.00903799, -0.01754417],\n",
       "       ...,\n",
       "       [-0.03163749,  0.03186156, -0.02637229, ...,  0.01529587,\n",
       "        -0.02140011,  0.00592547],\n",
       "       [-0.06485079,  0.12010214, -0.00485814, ..., -0.0044864 ,\n",
       "        -0.00994512,  0.00263873],\n",
       "       [-0.0317417 ,  0.03143238, -0.05164232, ...,  0.0148876 ,\n",
       "        -0.00766979,  0.00970931]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# our adjacency matrix\n",
    "print(\"Adjacency Matrix:\")\n",
    "print(A)\n",
    "\n",
    "# Adjacency Matrix:\n",
    "# [[0. 1. 1. 0. 0. 1. 0. 0. 1. 1.]\n",
    "#  [1. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    "#  [1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "#  [0. 0. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
    "#  [0. 0. 0. 1. 0. 1. 0. 0. 0. 0.]\n",
    "#  [1. 0. 0. 1. 1. 0. 1. 1. 0. 0.]\n",
    "#  [0. 0. 0. 0. 0. 1. 0. 1. 0. 0.]\n",
    "#  [0. 0. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
    "#  [1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
    "#  [1. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
    "\n",
    "# diagonal matrix\n",
    "D = np.diag(A.sum(axis=1))\n",
    "\n",
    "# graph laplacian\n",
    "L = D-A\n",
    "\n",
    "# eigenvalues and eigenvectors\n",
    "vals, vecs = np.linalg.eig(L)\n",
    "\n",
    "# sort these based on the eigenvalues\n",
    "vecs = vecs[:,np.argsort(vals)]\n",
    "vals = vals[np.argsort(vals)]\n",
    "\n",
    "# kmeans on first three vectors with nonzero eigenvalues\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(vecs[:,1:4])\n",
    "colors = kmeans.labels_\n",
    "\n",
    "print(\"Clusters:\", colors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinformatics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
